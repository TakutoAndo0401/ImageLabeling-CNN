{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (50000, 32, 32, 3)\n",
      "<class 'numpy.ndarray'> (10000, 32, 32, 3)\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "40000/40000 [==============================] - 11s 267us/step - loss: 2.9748 - val_loss: 2.9292\n",
      "Epoch 2/20\n",
      "40000/40000 [==============================] - 9s 237us/step - loss: 2.8722 - val_loss: 2.8345\n",
      "Epoch 3/20\n",
      "40000/40000 [==============================] - 10s 248us/step - loss: 2.7267 - val_loss: 2.6368\n",
      "Epoch 4/20\n",
      "40000/40000 [==============================] - 10s 255us/step - loss: 2.5777 - val_loss: 2.5498\n",
      "Epoch 5/20\n",
      "40000/40000 [==============================] - 10s 252us/step - loss: 2.4858 - val_loss: 2.4232\n",
      "Epoch 6/20\n",
      "40000/40000 [==============================] - 10s 249us/step - loss: 2.4099 - val_loss: 2.3769\n",
      "Epoch 7/20\n",
      "40000/40000 [==============================] - 10s 255us/step - loss: 2.3542 - val_loss: 2.3515\n",
      "Epoch 8/20\n",
      "40000/40000 [==============================] - 10s 248us/step - loss: 2.3022 - val_loss: 2.2965\n",
      "Epoch 9/20\n",
      "40000/40000 [==============================] - 11s 286us/step - loss: 2.2622 - val_loss: 2.3068\n",
      "Epoch 10/20\n",
      "40000/40000 [==============================] - 10s 244us/step - loss: 2.2150 - val_loss: 2.3016\n",
      "Epoch 11/20\n",
      "40000/40000 [==============================] - 10s 244us/step - loss: 2.1754 - val_loss: 2.2133\n",
      "Epoch 12/20\n",
      "40000/40000 [==============================] - 10s 252us/step - loss: 2.1358 - val_loss: 2.1647\n",
      "Epoch 13/20\n",
      "40000/40000 [==============================] - 12s 289us/step - loss: 2.0957 - val_loss: 2.1755\n",
      "Epoch 14/20\n",
      "40000/40000 [==============================] - 10s 248us/step - loss: 2.0659 - val_loss: 2.1621\n",
      "Epoch 15/20\n",
      "40000/40000 [==============================] - 10s 257us/step - loss: 2.0319 - val_loss: 2.1011\n",
      "Epoch 16/20\n",
      "40000/40000 [==============================] - 10s 241us/step - loss: 2.0008 - val_loss: 2.1059\n",
      "Epoch 17/20\n",
      "40000/40000 [==============================] - 9s 236us/step - loss: 1.9760 - val_loss: 2.0182\n",
      "Epoch 18/20\n",
      "40000/40000 [==============================] - 10s 240us/step - loss: 1.9481 - val_loss: 2.0438\n",
      "Epoch 19/20\n",
      "40000/40000 [==============================] - 9s 235us/step - loss: 1.9209 - val_loss: 2.0253\n",
      "Epoch 20/20\n",
      "40000/40000 [==============================] - 10s 240us/step - loss: 1.8954 - val_loss: 1.9877\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage import io\n",
    "from keras import utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import optimizers\n",
    "\n",
    "labels= pd.read_csv(\"train_master.tsv\", sep=\"\\t\")\n",
    "master = pd.read_csv(\"label_master.tsv\", sep=\"\\t\")\n",
    "sample = pd.read_csv(\"sample_submit.csv\", header=None, sep=\",\")\n",
    "\n",
    "train_images = []\n",
    "for fname in labels[\"file_name\"]:\n",
    "    path = \"./train/\" + fname\n",
    "    img = io.imread(path)\n",
    "    train_images.append(img)\n",
    "train_images = np.array(train_images)\n",
    "print(type(train_images), train_images.shape)\n",
    "\n",
    "test_images = []\n",
    "for fname in sample[0]:\n",
    "    path = \"./test/\" + fname\n",
    "    img = io.imread(path)\n",
    "    test_images.append(img)\n",
    "test_images = np.array(test_images )\n",
    "print(type(test_images ), test_images.shape)\n",
    "\n",
    "train_images = train_images / 255\n",
    "test_images = test_images / 255\n",
    "\n",
    "y = labels[\"label_id\"]\n",
    "\n",
    "y_categorical = utils.to_categorical(y)\n",
    "y_categorical\n",
    "\n",
    "X_con_image, X_ver_image = np.split(train_images, [40000])\n",
    "y_con_label, y_ver_label = np.split(y_categorical, [40000])\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=6, kernel_size=(3,3), padding=\"same\", input_shape=(32,32,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=12, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=24, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=240))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(units=140))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(units=40))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(units=20))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "             optimizer=optimizers.SGD(lr=0.005, momentum=0.9, decay=0.0, nesterov=True))\n",
    "\n",
    "batch_size=300\n",
    "epochs=20\n",
    "\n",
    "history = model.fit(X_con_image, y_con_label,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_ver_image, y_ver_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5d8b0ca42a9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mlearning_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "def learning_plot(history, epochs):\n",
    "    fig = plt.figure(figsize=(15,5))\n",
    "    plt.subplot(1,1,1)\n",
    "    plt.plot(range(1,epochs+1), history.history['loss'])\n",
    "    plt.plot(range(1,epochs+1), history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.xticks(range(1,epochs+1))\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['Construction', 'Verification'], loc='upper right')\n",
    "    plt.show()\n",
    "    \n",
    "learning_plot(history,epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 142us/step\n",
      "1.9876531745910644\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(X_ver_image ,y_ver_label  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 16 15 ... 15  8  2]\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(test_images)\n",
    "\n",
    "pred = pred.argmax(axis=1)\n",
    "print(pred)\n",
    "\n",
    "sample[1] = pred\n",
    "sample.to_csv(\"submit6.csv\", sep=\",\", index=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
